{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1767716505135,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "jJ7ay3Mv_Qvf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Feature Extraction Techniques\n",
    "\n",
    "This notebook covers all major feature extraction methods in NLP:\n",
    "1. **Bag of Words (CountVectorizer)**\n",
    "2. **TF-IDF Vectorizer**\n",
    "3. **N-grams (Unigram, Bigram, Trigram)**\n",
    "4. **Binary Bag of Words**\n",
    "5. **Word2Vec**\n",
    "6. **Hashing Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1767716665332,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "OTdgTveAHRyq"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text':['people watch campusx', 'campusx watch campusx', 'people write comment', 'campusx write comment'], 'output':[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1767716670204,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "mLPONCUBH2rM",
    "outputId": "9a567baf-e9c1-4a60-eaea-f40ee9402e36"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"campusx watch campusx\",\n          \"campusx write comment\",\n          \"people watch campusx\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-31d9c015-dafd-46df-ab2c-55745214519d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campusx watch campusx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campusx write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31d9c015-dafd-46df-ab2c-55745214519d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-31d9c015-dafd-46df-ab2c-55745214519d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-31d9c015-dafd-46df-ab2c-55745214519d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-17e8fd03-7531-4b38-bece-7de80766b406\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17e8fd03-7531-4b38-bece-7de80766b406')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-17e8fd03-7531-4b38-bece-7de80766b406 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                    text  output\n",
       "0   people watch campusx       1\n",
       "1  campusx watch campusx       1\n",
       "2   people write comment       0\n",
       "3  campusx write comment       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1767716695579,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "fliYkrbnH8fo"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1767716731744,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "CpE27mkHH_sC"
   },
   "outputs": [],
   "source": [
    "bou = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1767716761817,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "g8owGWRoIK4D",
    "outputId": "007a5a75-3d57-45d7-9cd3-d4957ed21064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campusx': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "# print vocabulary\n",
    "\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1767716818784,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "Ip_0Z4VyIS9P",
    "outputId": "d606c4fd-5a8e-4767-ef81-4e35005de475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bou[0].toarray())\n",
    "print(bou[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1767716833410,
     "user": {
      "displayName": "Muhammad Shibli",
      "userId": "07847958448912945819"
     },
     "user_tz": -360
    },
    "id": "iQGfOPfZIgx1",
    "outputId": "372b7ecf-657b-46e4-925f-4062f89625ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(['campusx watch and write comment of campusx']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bag of Words (CountVectorizer) - Already Demonstrated Above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TF-IDF Vectorizer (Term Frequency - Inverse Document Frequency)\n",
    "TF-IDF reflects how important a word is to a document in a collection. It penalizes common words and rewards rare but important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = tfidf.fit_transform(df['text'])\n",
    "\n",
    "# Display vocabulary\n",
    "print(\"TF-IDF Vocabulary:\")\n",
    "print(tfidf.vocabulary_)\n",
    "print(\"\\nFeature Names:\", tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display TF-IDF Matrix as DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF Matrix:\")\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform new text using TF-IDF\n",
    "new_text = ['campusx watch and write comment of campusx']\n",
    "tfidf_new = tfidf.transform(new_text)\n",
    "print(\"TF-IDF for new text:\")\n",
    "print(tfidf_new.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. N-grams (Unigram, Bigram, Trigram)\n",
    "N-grams capture word sequences. Unigram (n=1), Bigram (n=2), Trigram (n=3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram (single words) - default\n",
    "cv_unigram = CountVectorizer(ngram_range=(1, 1))\n",
    "unigram_matrix = cv_unigram.fit_transform(df['text'])\n",
    "print(\"Unigram Features:\", cv_unigram.get_feature_names_out())\n",
    "print(\"Unigram Matrix:\\n\", unigram_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigram (two consecutive words)\n",
    "cv_bigram = CountVectorizer(ngram_range=(2, 2))\n",
    "bigram_matrix = cv_bigram.fit_transform(df['text'])\n",
    "print(\"Bigram Features:\", cv_bigram.get_feature_names_out())\n",
    "print(\"\\nBigram Matrix:\\n\", bigram_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram (three consecutive words)\n",
    "cv_trigram = CountVectorizer(ngram_range=(3, 3))\n",
    "trigram_matrix = cv_trigram.fit_transform(df['text'])\n",
    "print(\"Trigram Features:\", cv_trigram.get_feature_names_out())\n",
    "print(\"\\nTrigram Matrix:\\n\", trigram_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined N-grams (Unigram + Bigram + Trigram)\n",
    "cv_combined = CountVectorizer(ngram_range=(1, 3))\n",
    "combined_matrix = cv_combined.fit_transform(df['text'])\n",
    "print(\"Combined N-gram Features:\", cv_combined.get_feature_names_out())\n",
    "print(\"\\nCombined N-gram Matrix Shape:\", combined_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binary Bag of Words\n",
    "Instead of word counts, it uses 1 if word is present, 0 if absent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Bag of Words\n",
    "cv_binary = CountVectorizer(binary=True)\n",
    "binary_matrix = cv_binary.fit_transform(df['text'])\n",
    "\n",
    "print(\"Binary BoW Features:\", cv_binary.get_feature_names_out())\n",
    "print(\"\\nBinary Matrix:\")\n",
    "binary_df = pd.DataFrame(binary_matrix.toarray(), columns=cv_binary.get_feature_names_out())\n",
    "binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Regular BoW vs Binary BoW for repeated words\n",
    "test_text = ['campusx watch campusx']  # 'campusx' appears twice\n",
    "\n",
    "# Regular Count\n",
    "regular_count = cv.transform(test_text)\n",
    "print(\"Regular BoW (count):\", regular_count.toarray())\n",
    "\n",
    "# Binary Count\n",
    "binary_count = cv_binary.transform(test_text)\n",
    "print(\"Binary BoW (0/1):\", binary_count.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hashing Vectorizer\n",
    "A memory-efficient alternative to CountVectorizer. Uses hashing to map words to features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Initialize Hashing Vectorizer with fixed number of features\n",
    "hv = HashingVectorizer(n_features=10, alternate_sign=False)\n",
    "hash_matrix = hv.fit_transform(df['text'])\n",
    "\n",
    "print(\"Hashing Vectorizer Matrix Shape:\", hash_matrix.shape)\n",
    "print(\"\\nHashing Matrix:\")\n",
    "print(hash_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Word2Vec (Word Embeddings)\n",
    "Word2Vec creates dense vector representations that capture semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenize the text\n",
    "tokenized_text = [text.split() for text in df['text']]\n",
    "print(\"Tokenized Text:\", tokenized_text)\n",
    "\n",
    "# Train Word2Vec model\n",
    "# vector_size: dimension of word vectors\n",
    "# window: context window size\n",
    "# min_count: minimum word frequency\n",
    "# sg: 0 for CBOW, 1 for Skip-gram\n",
    "w2v_model = Word2Vec(sentences=tokenized_text, vector_size=5, window=2, min_count=1, sg=0)\n",
    "\n",
    "print(\"\\nWord2Vec Vocabulary:\", list(w2v_model.wv.key_to_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vector for a specific word\n",
    "word = 'campusx'\n",
    "print(f\"Vector for '{word}':\")\n",
    "print(w2v_model.wv[word])\n",
    "\n",
    "# Find similar words\n",
    "print(f\"\\nWords similar to '{word}':\")\n",
    "print(w2v_model.wv.most_similar(word, topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document vectors by averaging word vectors\n",
    "def get_document_vector(text, model):\n",
    "    words = text.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    return np.zeros(model.vector_size)\n",
    "\n",
    "# Get document vectors for all texts\n",
    "doc_vectors = np.array([get_document_vector(text, w2v_model) for text in df['text']])\n",
    "print(\"Document Vectors Shape:\", doc_vectors.shape)\n",
    "print(\"\\nDocument Vectors:\")\n",
    "print(doc_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Word2Vec - Skip-gram Model\n",
    "Skip-gram predicts context words from the target word (opposite of CBOW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip-gram model (sg=1)\n",
    "w2v_skipgram = Word2Vec(sentences=tokenized_text, vector_size=5, window=2, min_count=1, sg=1)\n",
    "\n",
    "print(\"Skip-gram Word2Vec Vocabulary:\", list(w2v_skipgram.wv.key_to_index.keys()))\n",
    "print(f\"\\nVector for 'campusx' (Skip-gram):\")\n",
    "print(w2v_skipgram.wv['campusx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. One-Hot Encoding\n",
    "Each word is represented as a binary vector with only one 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for words\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Get all unique words\n",
    "all_words = ' '.join(df['text']).split()\n",
    "unique_words = list(set(all_words))\n",
    "print(\"Unique Words:\", unique_words)\n",
    "\n",
    "# Label encode first\n",
    "le = LabelEncoder()\n",
    "integer_encoded = le.fit_transform(unique_words)\n",
    "\n",
    "# One-hot encode\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded = integer_encoded.reshape(-1, 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "# Display as DataFrame\n",
    "onehot_df = pd.DataFrame(onehot_encoded, index=unique_words, columns=[f'dim_{i}' for i in range(len(unique_words))])\n",
    "print(\"\\nOne-Hot Encoding:\")\n",
    "onehot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Character-level N-grams\n",
    "Extract features at character level instead of word level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character-level N-grams (useful for spelling variations, typos)\n",
    "cv_char = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
    "char_matrix = cv_char.fit_transform(df['text'])\n",
    "\n",
    "print(\"Character N-gram Features (first 20):\", cv_char.get_feature_names_out()[:20])\n",
    "print(\"\\nTotal Character Features:\", len(cv_char.get_feature_names_out()))\n",
    "print(\"Matrix Shape:\", char_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Additional Parameters & Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features: Limit vocabulary size to top N most frequent\n",
    "cv_max = CountVectorizer(max_features=3)\n",
    "max_matrix = cv_max.fit_transform(df['text'])\n",
    "print(\"Max Features (top 3 most frequent):\", cv_max.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_df and max_df: Control document frequency thresholds\n",
    "# min_df=2: word must appear in at least 2 documents\n",
    "# max_df=0.9: word must appear in less than 90% of documents\n",
    "cv_df = CountVectorizer(min_df=2, max_df=0.9)\n",
    "df_matrix = cv_df.fit_transform(df['text'])\n",
    "print(\"With min_df=2, max_df=0.9:\", cv_df.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words removal\n",
    "cv_stop = CountVectorizer(stop_words='english')\n",
    "stop_matrix = cv_stop.fit_transform(df['text'])\n",
    "print(\"Without English stop words:\", cv_stop.get_feature_names_out())\n",
    "\n",
    "# Custom stop words\n",
    "custom_stops = ['watch', 'write']\n",
    "cv_custom = CountVectorizer(stop_words=custom_stops)\n",
    "custom_matrix = cv_custom.fit_transform(df['text'])\n",
    "print(\"Without custom stop words:\", cv_custom.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tokenizer with preprocessing\n",
    "import re\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    # Convert to lowercase and extract words\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b[a-z]+\\b', text)\n",
    "    return tokens\n",
    "\n",
    "cv_custom_token = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "custom_token_matrix = cv_custom_token.fit_transform(df['text'])\n",
    "print(\"Custom Tokenizer Features:\", cv_custom_token.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table comparing all feature extraction methods\n",
    "summary_data = {\n",
    "    'Method': [\n",
    "        'Bag of Words', \n",
    "        'TF-IDF', \n",
    "        'Binary BoW', \n",
    "        'N-grams',\n",
    "        'Hashing Vectorizer',\n",
    "        'Word2Vec (CBOW)',\n",
    "        'Word2Vec (Skip-gram)',\n",
    "        'One-Hot Encoding',\n",
    "        'Character N-grams'\n",
    "    ],\n",
    "    'Type': ['Sparse', 'Sparse', 'Sparse', 'Sparse', 'Sparse', 'Dense', 'Dense', 'Sparse', 'Sparse'],\n",
    "    'Captures Semantics': ['No', 'No', 'No', 'Partial', 'No', 'Yes', 'Yes', 'No', 'No'],\n",
    "    'Memory Efficient': ['Medium', 'Medium', 'Medium', 'Low', 'High', 'Medium', 'Medium', 'Low', 'Low'],\n",
    "    'Best Use Case': [\n",
    "        'Simple text classification',\n",
    "        'Document ranking, search',\n",
    "        'Short texts, presence matters',\n",
    "        'Phrase detection',\n",
    "        'Large-scale streaming data',\n",
    "        'Semantic similarity (frequent words)',\n",
    "        'Semantic similarity (rare words)',\n",
    "        'Small vocabulary tasks',\n",
    "        'Spelling variations, typos'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"=== Feature Extraction Methods Comparison ===\\n\")\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNETxX0YgJdUP51JVG5dUGn",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
